{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0252ee88",
   "metadata": {},
   "source": [
    "# Hospitalisation Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6edf0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from config import Config as paths\n",
    "project_root = Path(\"..\").resolve()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from data_cleaning.renaming import (\n",
    "    generate_and_save_rename_columns_json,\n",
    "    rename_columns,\n",
    "    generate_and_save_rename_values_json,\n",
    "    rename_values,\n",
    ")\n",
    "from data_cleaning.cleaners.episode.episodeCleaner import EpisodeCleaner\n",
    "\n",
    "cleaner = EpisodeCleaner()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ede09bd",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b2b0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "melior_sva = pd.read_parquet(paths.MELIOR_SV_PATH)\n",
    "reference_data = pd.read_parquet(paths.REFERENCE_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ad245f",
   "metadata": {},
   "source": [
    "## Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9ea075",
   "metadata": {},
   "outputs": [],
   "source": [
    "melior_sva_renamed = rename_columns(\n",
    "    df = melior_sva, path = '../rename_files/hospitalisation/melior_sv_rename_columns.json'\n",
    ").drop_duplicates()\n",
    "\n",
    "melior_sva_renamed['hosp_start'] = melior_sva_renamed['hosp_start'].dt.tz_localize(None)\n",
    "melior_sva_renamed['hosp_stop'] = melior_sva_renamed['hosp_stop'].dt.tz_localize(None)\n",
    "\n",
    "melior_sva_renamed = melior_sva_renamed.dropna(subset=['hosp_start','hosp_stop'])\n",
    "melior_sva_renamed['patient_id'] = melior_sva_renamed['patient_id'].astype(int)\n",
    "reference_data['patient_id'] = reference_data['patient_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a252ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "melior_sva_without_ER = melior_sva_renamed[~melior_sva_renamed.hosp_site.str.contains('Aku|aku')].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92adb129",
   "metadata": {},
   "source": [
    "## Combine hospitalisations if overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13446f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_block_id(df, patient_id, start, stop, time=0):\n",
    "    \"\"\"\n",
    "    Function for assigning block ids to overlapping time periods for each patient. This is useful for combining overlapping hospitalisations\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : _type_\n",
    "        Dataframe containing dates\n",
    "    patient_id : _type_\n",
    "        column name of the column containing patient ids\n",
    "    start : _type_\n",
    "        column name of the column containing the start dates\n",
    "    stop : _type_\n",
    "        column name of the column containing the stop dates\n",
    "    time : int, optional\n",
    "        Minimum time gap between hospitalisations, by default 0\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Original DataFrame with an additional column \"block_id\" indicating overlapping periods.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    start_date = start + '_date'\n",
    "    stop_date = stop + '_date'\n",
    "\n",
    "    df[start_date] = df[start].dt.normalize()\n",
    "    df[stop_date] = df[stop].dt.normalize()\n",
    "    df = df.sort_values([patient_id, start_date, stop_date]).reset_index(drop=True)\n",
    "\n",
    "    prev_max_end = df.groupby(patient_id)[stop_date].cummax().shift()\n",
    "    new_block = (df[start_date] > (prev_max_end + pd.Timedelta(days=time))) | prev_max_end.isna()\n",
    "    df[\"block_id\"] = new_block.groupby(df[patient_id]).cumsum()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48be7dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "melior_sva_combined = assign_block_id(melior_sva_renamed, 'patient_id', 'hosp_start', 'hosp_stop', time=0)\n",
    "\n",
    "melior_sva_combined = melior_sva_combined.groupby(['patient_id', 'block_id']).agg({\n",
    "    'patient_id': 'first',\n",
    "    'hosp_start': 'min',\n",
    "    'hosp_stop': 'max',\n",
    "    'hosp_site': lambda x: ' | '.join(x.dropna().unique()),\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "\n",
    "melior_sva_without_ER_combined = assign_block_id(melior_sva_without_ER, 'patient_id', 'hosp_start', 'hosp_stop', time=0)\n",
    "\n",
    "melior_sva_without_ER_combined = melior_sva_without_ER_combined.groupby(['patient_id', 'block_id']).agg({\n",
    "    'patient_id': 'first',\n",
    "    'hosp_start': 'min',\n",
    "    'hosp_stop': 'max',\n",
    "    'hosp_site': lambda x: ' | '.join(x.dropna().unique()),\n",
    "}).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7000c90",
   "metadata": {},
   "source": [
    "## Find hospitalisation with culture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3104e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "hosp_with_episode = melior_sva_combined.merge(\n",
    "    reference_data[['episode_id','sample_date','patient_id']].dropna().drop_duplicates(),\n",
    "    on='patient_id',\n",
    "    how='right'\n",
    ")\n",
    "\n",
    "\n",
    "hosp_with_episode_with_culture = hosp_with_episode[hosp_with_episode.sample_date.between(hosp_with_episode.hosp_start - pd.Timedelta(days=3), hosp_with_episode.hosp_stop + pd.Timedelta(days=3))].copy()\n",
    "hosp_with_episode_with_culture = hosp_with_episode_with_culture.sort_values(['episode_id', 'hosp_stop'],ascending=[True,False]).drop_duplicates('episode_id')\n",
    "hosp_with_episode_with_culture = hosp_with_episode_with_culture.rename(columns={\n",
    "    'hosp_start': 'hosp_start_with_culture',\n",
    "    'hosp_stop': 'hosp_stop_with_culture',\n",
    "    'hosp_site': 'hosp_site_with_culture'\n",
    "})\n",
    "hosp_with_episode_with_culture = hosp_with_episode_with_culture[['episode_id', 'hosp_start_with_culture', 'hosp_stop_with_culture', 'hosp_site_with_culture']].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdad7e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "hosp_without_ER_with_episodes = melior_sva_without_ER_combined.merge(\n",
    "        reference_data[['episode_id','sample_date','patient_id']].dropna().drop_duplicates(),\n",
    "    on='patient_id',\n",
    "    how='right'\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "hosp_without_ER_with_culture = hosp_without_ER_with_episodes[hosp_without_ER_with_episodes.sample_date.between(hosp_without_ER_with_episodes.hosp_start - pd.Timedelta(days=3), hosp_without_ER_with_episodes.hosp_stop + pd.Timedelta(days=3))].copy()\n",
    "hosp_without_ER_with_culture = hosp_without_ER_with_culture.sort_values(['episode_id', 'hosp_stop'],ascending=[True,False]).drop_duplicates('episode_id')\n",
    "hosp_without_ER_with_culture = hosp_without_ER_with_culture.rename(columns={\n",
    "    'hosp_start': 'hosp_start_with_culture',\n",
    "    'hosp_stop': 'hosp_stop_with_culture',\n",
    "    'hosp_site': 'hosp_site_with_culture'\n",
    "})\n",
    "hosp_without_ER_with_culture = hosp_without_ER_with_culture[['episode_id', 'hosp_start_with_culture', 'hosp_stop_with_culture', 'hosp_site_with_culture']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb670b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hosp_with_episode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07860a4",
   "metadata": {},
   "source": [
    "## Calculate hospitalisation times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40c34d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hospitalisation_times(df, unique_id, all_unique_ids, baseline, start, stop, time, window_direction=\"after\"):\n",
    "    df = df.copy()\n",
    "\n",
    "    for col in [baseline, start, stop]:\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "\n",
    "    start_date = start + \"_date\"\n",
    "    stop_date = stop + \"_date\"\n",
    "    df[start_date] = df[start]\n",
    "    df[stop_date] = df[stop]\n",
    "    df[\"baseline_date\"] = df[baseline]\n",
    "\n",
    "    # choose if lookback or to look forward\n",
    "    if window_direction.lower() == \"after\":\n",
    "        window_start = df[\"baseline_date\"] + pd.Timedelta(days=1)\n",
    "        window_end = df[\"baseline_date\"] + pd.Timedelta(days=time)\n",
    "    elif window_direction.lower() == \"before\":\n",
    "        window_start = df[\"baseline_date\"] - pd.Timedelta(days=time)\n",
    "        window_end = df[\"baseline_date\"] - pd.Timedelta(days=1)\n",
    "    \n",
    "\n",
    "    # trunc dates\n",
    "    df[\"start_date_trunc\"] = df[start_date].clip(lower=window_start)\n",
    "    df[\"stop_date_trunc\"] = df[stop_date].clip(upper=window_end)\n",
    "\n",
    "    # number of days between dates\n",
    "    df[\"diff\"] = (df[\"stop_date_trunc\"] - df[\"start_date_trunc\"]).dt.days + 1\n",
    "\n",
    "    # Keep only valid periods\n",
    "    df = df[df[\"start_date_trunc\"] <= df[\"stop_date_trunc\"]]\n",
    "\n",
    "    # Sum days by episode\n",
    "    direction_suffix = \"prior\" if window_direction.lower() == \"before\" else \"after\"\n",
    "    column_name = f\"hosp_time_{direction_suffix}_{time}_days\"\n",
    "    \n",
    "    df_hosp_times = (\n",
    "        df.groupby(unique_id)\n",
    "        .agg({\"diff\": \"sum\"})\n",
    "        .reset_index()\n",
    "        .rename(columns={\"diff\": column_name})\n",
    "    )\n",
    "\n",
    "    # add rest of the episodes\n",
    "    #df_hosp_times = all_unique_ids.merge(df_hosp_times, on=unique_id, how=\"left\")\n",
    "    #df_hosp_times[column_name] = df_hosp_times[column_name].fillna(0).astype(int)\n",
    "    \n",
    "\n",
    "    return df_hosp_times\n",
    "\n",
    "\n",
    "\n",
    "# Calculate hospitalization time in 30-day window\n",
    "hosp_time_30_after = calculate_hospitalisation_times(\n",
    "    df = hosp_with_episode,\n",
    "    unique_id=\"episode_id\",\n",
    "    all_unique_ids = reference_data[['episode_id']].drop_duplicates(),\n",
    "    baseline=\"sample_date\",\n",
    "    start=\"hosp_start\",\n",
    "    stop=\"hosp_stop\",\n",
    "    time=30,\n",
    "    window_direction='after'\n",
    ")\n",
    "\n",
    "hosp_time_365_after = calculate_hospitalisation_times(\n",
    "    df = hosp_with_episode,\n",
    "    unique_id=\"episode_id\",\n",
    "    all_unique_ids = reference_data[['episode_id']].drop_duplicates(),\n",
    "    baseline=\"sample_date\",\n",
    "    start=\"hosp_start\",\n",
    "    stop=\"hosp_stop\",\n",
    "    time=365,\n",
    "    window_direction='after'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581cb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hosp_time_30_after.hosp_time_after_30_days.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252f1406",
   "metadata": {},
   "source": [
    "## Next hospitalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9d2a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# behåller enbart vårdtillfällen som händer efter provtagningsdatum\n",
    "next_hosp = hosp_without_ER_with_episodes[hosp_without_ER_with_episodes['hosp_start'] > hosp_without_ER_with_episodes['sample_date']].copy()\n",
    "\n",
    "# antalet dagar till nästa vårdtillfälle\n",
    "next_hosp['days_to_readmission'] = (next_hosp['hosp_start'] - next_hosp['sample_date']).dt.days\n",
    "\n",
    "# välj första vårdtillfället\n",
    "next_hosp = next_hosp.sort_values(['episode_id', 'hosp_start'])\n",
    "next_readmission = next_hosp.groupby('episode_id').first().reset_index()\n",
    "\n",
    "next_readmission = next_readmission[['episode_id', 'hosp_start', 'hosp_stop', 'hosp_site', 'days_to_readmission']].rename(columns={\n",
    "    'hosp_start': 'readmission_start',\n",
    "    'hosp_stop': 'readmission_stop',\n",
    "    'hosp_site': 'readmission_site'\n",
    "})\n",
    "\n",
    "next_readmission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1466b7d7",
   "metadata": {},
   "source": [
    "## Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61154966",
   "metadata": {},
   "outputs": [],
   "source": [
    "hosp_combined = hosp_without_ER_with_culture.copy()\n",
    "hosp_combined = pd.merge(hosp_times,hosp_combined,on='episode_id',how='outer')\n",
    "hosp_combined = pd.merge(hosp_combined,next_readmission,on='episode_id',how='outer')\n",
    "hosp_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab36627",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe06517",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(paths.STORE_PATH + \"/hospitalisation\"):\n",
    "    os.makedirs(paths.STORE_PATH + \"/hospitalisation\")\n",
    "#sva_cleaned.to_parquet(f\"{paths.STORE_PATH}/hospitalisation/hosp_sva_cleaned.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
